{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46092/2712690755.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pickle\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3\n",
    "# Adapted from https://github.com/MJeremy2017/reinforcement-learning-implementation/blob/master/TicTacToe/ticTacToe.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.boardHash = None\n",
    "        # init p1 plays first\n",
    "        self.playerSymbol = 1\n",
    "\n",
    "    # get unique hash of current board state\n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(BOARD_COLS * BOARD_ROWS))\n",
    "        return self.boardHash\n",
    "\n",
    "    def winner(self):\n",
    "        # row\n",
    "        for i in range(BOARD_ROWS):\n",
    "            if sum(self.board[i, :]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[i, :]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        # col\n",
    "        for i in range(BOARD_COLS):\n",
    "            if sum(self.board[:, i]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[:, i]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        # diagonal\n",
    "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
    "        diag_sum2 = sum([self.board[i, BOARD_COLS - i - 1] for i in range(BOARD_COLS)])\n",
    "        diag_sum = max(abs(diag_sum1), abs(diag_sum2))\n",
    "        if diag_sum == 3:\n",
    "            self.isEnd = True\n",
    "            if diag_sum1 == 3 or diag_sum2 == 3:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "\n",
    "        # tie\n",
    "        # no available positions\n",
    "        if len(self.availablePositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        # not end\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "\n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i, j))  # need to be tuple\n",
    "        return positions\n",
    "\n",
    "    def updateState(self, position):\n",
    "        self.board[position] = self.playerSymbol\n",
    "        # switch to another player\n",
    "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
    "\n",
    "    # only when game ends\n",
    "    def giveReward(self):\n",
    "        result = self.winner()\n",
    "        # backpropagate reward\n",
    "        if result == 1:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result == -1:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        else:\n",
    "            self.p1.feedReward(0.1)\n",
    "            self.p2.feedReward(0.5)\n",
    "\n",
    "    # board reset\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS))\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "\n",
    "    def play_train(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "            while not self.isEnd:\n",
    "                # self.showBoard()\n",
    "                # Player 1\n",
    "                positions = self.availablePositions()\n",
    "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                # take action and upate board state\n",
    "                self.updateState(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                # check board status if it is end\n",
    "\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    \n",
    "                    # ended with p1 either win or draw\n",
    "                    self.giveReward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # Player 2\n",
    "                    positions = self.availablePositions()\n",
    "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                    self.updateState(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "\n",
    "                    win = self.winner()\n",
    "                    if win is not None:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.giveReward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "\n",
    "    # play with human\n",
    "    def play2(self,display=False):\n",
    "        while not self.isEnd:\n",
    "            # Player 1\n",
    "            positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol,explore=False)\n",
    "            # take action and upate board state\n",
    "            self.updateState(p1_action)\n",
    "            # check board status if it is end\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    if display:\n",
    "                        self.showBoard()\n",
    "                    self.reset()\n",
    "                    return self.p1.name\n",
    "                else:\n",
    "                    if display:\n",
    "                        self.showBoard()\n",
    "                    self.reset()\n",
    "                    return 0\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Player 2\n",
    "                self.showBoard()\n",
    "                positions = self.availablePositions()\n",
    "                p2_action = self.p2.chooseAction(positions,self.board,self.playerSymbol,explore=False)\n",
    "\n",
    "                self.updateState(p2_action)\n",
    "                # self.showBoard()\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        self.reset()\n",
    "                        if display:\n",
    "                            self.showBoard()\n",
    "                        return self.p2.name\n",
    "                    else:\n",
    "                        if display:\n",
    "                            self.showBoard()\n",
    "                        self.reset()\n",
    "                        return 0\n",
    "                    break\n",
    "            if display:\n",
    "                self.showBoard()\n",
    "\n",
    "    def showBoard(self):\n",
    "        # p1: x  p2: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name\n",
    "        self.states = []  # record all positions taken\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {}  # state -> value\n",
    "\n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(BOARD_COLS * BOARD_ROWS))\n",
    "        return boardHash\n",
    "\n",
    "    def chooseAction(self, positions, current_board, symbol,explore=True):\n",
    "        if explore and np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "        else:\n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = self.getHash(next_board)\n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                # print(\"value\", value)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "        # print(\"{} takes action {}\".format(self.name, action))\n",
    "        return action\n",
    "\n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "\n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "\n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "\n",
    "    def savePolicy(self):\n",
    "        fw = open('policy_' + str(self.name), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "\n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file, 'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def chooseAction(self, positions,board,player_symbol=1,explore=False):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "            else:\n",
    "                print(\"Invalid Action\")\n",
    "\n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "\n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer(Player):\n",
    "    def chooseAction(self, positions, current_board, symbol,explore =True):\n",
    "        # return super().chooseAction(positions, current_board, symbol)\n",
    "        idx = np.random.choice(len(positions))\n",
    "        return positions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   | o | o | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "|   | x | x | \n",
      "-------------\n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "| x | o | o | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = Player(\"q_player\")\n",
    "# p2 = Player(\"rand_player\")\n",
    "p2 = HumanPlayer(\"Human\")\n",
    "# p2 = RandomPlayer('Random')\n",
    "p1.loadPolicy('policy_p1_vs_q')\n",
    "# p2.loadPolicy('policy_p1_vs_q')\n",
    "st = State(p1, p2)\n",
    "# print(\"training...\")\n",
    "# st.play_train(50000)\n",
    "# p1.savePolicy()\n",
    "st.play2(display=True)\n",
    "# st.showBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "st.showBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7278603efb34256810c90dabd1d5245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "NUM_TRIALS = 50000\n",
    "winners = []\n",
    "for i in tqdm(range(NUM_TRIALS)):\n",
    "    winners.append(st.play2())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms, wins = np.unique(winners,return_counts=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 1 artists>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.bar(nms,[w / np.sum(wins) for w in wins])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
