{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.signal import convolve2d\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(board):\n",
    "    plt.axes()\n",
    "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
    "    circles=[]\n",
    "    for i,row in enumerate(board):\n",
    "        for j,val in enumerate(row):\n",
    "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
    "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
    "\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    for circle in circles:\n",
    "        plt.gca().add_patch(circle)\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Player class\n",
    "This is to be inherited and treated as a virtual class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasePlayer:\n",
    "    def __init__(self,player_symbol) -> None:\n",
    "        self.player_symbol = player_symbol\n",
    "        self.num_rows = 0\n",
    "        self.num_cols = 0\n",
    "    def choose_action(self,valid_actions=None,board=None):\n",
    "        raise NotImplementedError(\"Player class is virtual, please inherent from it\")\n",
    "    def give_reward(self,reward):\n",
    "        raise NotImplementedError(\"Player class is virtual, please inherent from it\")\n",
    "    def reset(self):\n",
    "        raise NotImplementedError(\"Player class is virtual, please inherent from it\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer(BasePlayer):\n",
    "    def __init__(self, player_symbol) -> None:\n",
    "        super().__init__(player_symbol)\n",
    "    def choose_action(self, valid_actions=None, board=None):\n",
    "        return np.random.choice(valid_actions)\n",
    "    def give_reward(self, reward):\n",
    "        pass\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACTION_REASONING(Enum):\n",
    "    RANDOM = 1\n",
    "    POLICY = 2\n",
    "\n",
    "class QPlayer(BasePlayer):\n",
    "    def __init__(self, player_symbol,epsilon = 0.5,prop_factor=0.5,alpha=0.4) -> None:\n",
    "        super().__init__(player_symbol)\n",
    "        self.initial_epsilon = epsilon\n",
    "        self.epsilon = epsilon\n",
    "        self.action_history = []\n",
    "        self.action_reasoning = []\n",
    "        self.board_history = []\n",
    "        self.alpha = alpha\n",
    "        self.prop_factor = prop_factor\n",
    "        self.q_table = {}\n",
    "    def get_board_hash(self,board):\n",
    "        return str(board)\n",
    "    def choose_action(self, valid_actions=None, board=None):\n",
    "        action = None\n",
    "        \n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.choice(valid_actions)\n",
    "            self.action_history.append(action)\n",
    "            self.action_reasoning.append(ACTION_REASONING.RANDOM)\n",
    "            self.board_history.append(board)\n",
    "        else:\n",
    "            st_reward = self.q_table.get(self.get_board_hash(board),None)\n",
    "            if st_reward:\n",
    "                action = np.random.choice(np.where(st_reward == max(st_reward))[0]) #Choose a random action from all actions that have the highest q values\n",
    "                self.action_history.append(action)\n",
    "                self.action_reasoning.append(ACTION_REASONING.POLICY)\n",
    "                self.board_history.append(board)\n",
    "\n",
    "            else:\n",
    "                action = np.random.choice(valid_actions)\n",
    "                self.action_history.append(action)\n",
    "                self.action_reasoning.append(ACTION_REASONING.POLICY)\n",
    "                self.board_history.append(board)\n",
    "\n",
    "        return action\n",
    "    def reset(self):\n",
    "        self.epsilon = self.initial_epsilon\n",
    "        self.action_history = []\n",
    "        self.action_reasoning = []\n",
    "        self.board_history = []\n",
    "    \n",
    "    def give_reward(self, reward):\n",
    "        for i,(action,reason,board) in enumerate(zip(reversed(self.action_history),reversed(self.action_reasoning),reversed(self.board_history))): #Iterate over all action,board,reasons backwards from start\n",
    "            if reason == ACTION_REASONING.RANDOM:\n",
    "                i = i -1\n",
    "                continue\n",
    "\n",
    "\n",
    "            st_reward = self.q_table.get(self.get_board_hash(board))\n",
    "            if st_reward:\n",
    "                st_reward[action] = st_reward[action] * (1-self.alpha) + (self.alpha * )\n",
    "            else:\n",
    "                self.q_table[self.get_board_hash(board)] = [reward * np.pow(self.prop_factor,i) if j == action else 0 for j in range(self.num_cols)]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = ['a','b','c']\n",
    "for j,x in enumerate(a):\n",
    "    print(j,x)\n",
    "    if x == 2:\n",
    "        j = j -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.array([0.9,0.9,0.7,0.5])\n",
    "np.argmax(tmp)\n",
    "np.where(tmp == max(tmp))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Board Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Board:\n",
    "    def __init__(self,p1:BasePlayer,p2:BasePlayer,num_rows=7,num_cols=7):\n",
    "        self.num_rows= num_rows\n",
    "        self.num_cols = num_cols\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.p1.num_rows = num_rows\n",
    "        self.p1.num_cols = num_cols\n",
    "        self.p2.num_rows = num_rows\n",
    "        self.p2.num_cols = num_cols\n",
    "        self.board = np.zeros(shape=(num_rows,num_cols),dtype=int)\n",
    "    def check_win(self):\n",
    "        \n",
    "        if(len(self.get_valid_moves()) == 0): return None\n",
    "        horizontal_kernel = np.array([[ 1, 1, 1, 1]])\n",
    "        vertical_kernel = np.transpose(horizontal_kernel)\n",
    "        diag1_kernel = np.eye(4, dtype=np.uint8)\n",
    "        diag2_kernel = np.fliplr(diag1_kernel)\n",
    "        detection_kernels = [horizontal_kernel, vertical_kernel, diag1_kernel, diag2_kernel]\n",
    "        for kernel in detection_kernels:\n",
    "\n",
    "            a = convolve2d(self.board,kernel,mode='valid')\n",
    "            if( (a == 4).any()):\n",
    "                return 1\n",
    "            if ((a == -4).any()):\n",
    "                return -1\n",
    "            \n",
    "            # print(a.any())\n",
    "        return 0\n",
    "    def get_valid_moves(self):\n",
    "        return [i for i,j in enumerate(self.board[0]) if j == 0]\n",
    "    def reset(self):\n",
    "        self.board = np.zeros(shape=(self.num_rows,self.num_cols))\n",
    "    def __str__(self) -> str:\n",
    "        visualize(self.board)\n",
    "        return \"\"\n",
    "    def place(self,move,player_symbol=1):\n",
    "        if move not in self.get_valid_moves():\n",
    "            raise RuntimeError(f\"Invalid Action {move} with board state: \\n{str(self.board)}\")\n",
    "        col = self.board[:,move]\n",
    "        idx = int(np.where(col == 0)[0][-1])\n",
    "        col[idx] = player_symbol\n",
    "    def play_agents(self,verbose=True):\n",
    "        \n",
    "        while self.check_win() == 0:\n",
    "            valid_actions = self.get_valid_moves()\n",
    "            p1_action = self.p1.choose_action(valid_actions=valid_actions,board=self.board)\n",
    "            self.place(p1_action,player_symbol=self.p1.player_symbol)\n",
    "\n",
    "            if verbose:\n",
    "                print(self)\n",
    "            if self.check_win() == self.p1.player_symbol:\n",
    "                print(f\"Player {self.p1.player_symbol} Wins!\")\n",
    "                return self.p1.player_symbol\n",
    "            else:\n",
    "                valid_actions = self.get_valid_moves()\n",
    "                p2_action = self.p2.choose_action(valid_actions=valid_actions,board=self.board)\n",
    "                self.place(p2_action,player_symbol=self.p2.player_symbol)\n",
    "\n",
    "                if verbose:\n",
    "                    print(self)\n",
    "\n",
    "                if self.check_win() == self.p2.player_symbol:\n",
    "                    print(f\"Player {self.p2.player_symbol} Wins!\")\n",
    "                    return self.p2.player_symbol\n",
    "\n",
    "        return self.check_win()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
